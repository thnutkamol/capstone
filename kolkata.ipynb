{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "import ipywidgets as wgt\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = '3mBQlhZHYSvrS37Nt47CNuDAH'\n",
    "api_secret = 'ZmGYg594O5AVABdYFRM8QkIaubVDauRfpncALnm9ilaBZL47h8'\n",
    "access_token = '1065785581601345536-LLAnqdBWVk5NQ3P2TOfxv87RDn0spJ'\n",
    "access_token_secret = 'MMwkQHuZNH5WoYOsAy300iPdw4f8YMuPCKRhQ7Uw0Jngg'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "col = pymongo.MongoClient()[\"twitter\"][\"kolkata1\"]\n",
    "col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ec6c49a5cc4630b7e4596031d59c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5941f7f7b54e45089a24907206716e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<span class=\"label label-primary\">Tweets/Sec: 0.0</span>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    def __init__(self, max_tweets=5000, *args, **kwargs):\n",
    "        self.max_tweets = max_tweets\n",
    "        self.counter = 0\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def on_connect(self):\n",
    "        self.counter = 0\n",
    "        self.start_time = datetime.now()\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        # Increment counter\n",
    "        self.counter += 1\n",
    "        \n",
    "        # Store tweet to MongoDB\n",
    "        col.insert_one(status._json)\n",
    "        \n",
    "        \n",
    "        if self.counter % 1 == 0:\n",
    "            value = int(100.00 * self.counter / self.max_tweets)\n",
    "            mining_time = datetime.now() - self.start_time\n",
    "            progress_bar.value = value\n",
    "            html_value = \"\"\"<span class=\"label label-primary\">Tweets/Sec: %.1f</span>\"\"\" % (self.counter / max([1,mining_time.seconds]))\n",
    "            html_value += \"\"\" <span class=\"label label-success\">Progress: %.1f%%</span>\"\"\" % (self.counter / self.max_tweets * 100.0)\n",
    "            html_value += \"\"\" <span class=\"label label-info\">ETA: %.1f Sec</span>\"\"\" % ((self.max_tweets - self.counter) / (self.counter / max([1,mining_time.seconds])))\n",
    "            wgt_status.value = html_value\n",
    "            #print(\"%s/%s\" % (self.counter, self.max_tweets))\n",
    "            if self.counter >= self.max_tweets:\n",
    "                myStream.disconnect()\n",
    "                print(\"Finished\")\n",
    "                print(\"Total Mining Time: %s\" % (mining_time))\n",
    "                print(\"Tweets/Sec: %.1f\" % (self.max_tweets / mining_time.seconds))\n",
    "                progress_bar.value = 0\n",
    "                \n",
    "    \n",
    "myStreamListener = MyStreamListener(max_tweets=5000)\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n",
    "keywords = [\"Kolkata Knight Riders\",\n",
    "            \"KolkataKnightRiders\",\n",
    "            \"KKR\"\n",
    "           ]\n",
    "\n",
    "# Visualize a progress bar to track progress\n",
    "progress_bar = wgt.IntProgress(value=0)\n",
    "display(progress_bar)\n",
    "wgt_status = wgt.HTML(value=\"\"\"<span class=\"label label-primary\">Tweets/Sec: 0.0</span>\"\"\")\n",
    "display(wgt_status)\n",
    "\n",
    "# Start a filter with an error counter of 20\n",
    "for error_counter in range(20):\n",
    "    try:\n",
    "        myStream.filter(track=keywords)\n",
    "        print(\"Tweets collected: %s\" % myStream.listener.counter)\n",
    "        print(\"Total tweets in collection: %s\" % col.count())\n",
    "        break\n",
    "    except:\n",
    "        print(\"ERROR# %s\" % (error_counter + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [{\"created_at\": item[\"created_at\"],\n",
    "            \"text\": item[\"text\"],\n",
    "            \"user\": \"@%s\" % item[\"user\"][\"screen_name\"],\n",
    "            \"source\": item[\"source\"],\n",
    "            \"lang\":item[\"lang\"],\n",
    "            \n",
    "           } for item in col.find()]\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(dataset.text)\n",
    "\n",
    "word_count = pd.DataFrame(cv.get_feature_names(), columns=[\"word\"])\n",
    "word_count[\"count\"] = count_matrix.sum(axis=0).tolist()[0]\n",
    "word_count = word_count.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "word_count[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_name(x):\n",
    "    value = re.findall(pattern=\"<[^>]+>([^<]+)</a>\", string=x)\n",
    "    if len(value) > 0:\n",
    "        return value[0]\n",
    "    else:\n",
    "        return \"\"\n",
    "dataset.source_name = dataset.source.apply(get_source_name)\n",
    "\n",
    "source_counts = dataset.source_name.value_counts().sort_values()[-10:]\n",
    "\n",
    "bottom = [index for index, item in enumerate(source_counts.index)]\n",
    "plt.barh(bottom, width=source_counts, color=\"blue\", linewidth=0)\n",
    "\n",
    "y_labels = [\"%s %.1f%%\" % (item, 100.0*source_counts[item]/len(dataset)) for index,item in enumerate(source_counts.index)]\n",
    "plt.yticks(np.array(bottom)+0.4, y_labels)\n",
    "\n",
    "source_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_counts = dataset.lang.value_counts().sort_values()[-10:]\n",
    "bottom = [index for index, item in enumerate(lang_counts.index)]\n",
    "plt.barh(bottom, width=lang_counts, color=\"green\", linewidth=0)\n",
    "y_labels = [\"%s %.1f%%\" % (item, 100.0*lang_counts[item]/len(dataset)) for index,item in enumerate(lang_counts.index)]\n",
    "plt.yticks(np.array(bottom)+0.4, y_labels)\n",
    "lang_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = [{\"id\": item[\"id\"],\n",
    "            \"text\": item[\"text\"],\n",
    "            \"lang\":item[\"lang\"],\n",
    "            \n",
    "           } for item in col.find()]\n",
    "\n",
    "dataset1 = pd.DataFrame(dataset1)\n",
    "is_dataset1=dataset1.lang==\"en\"\n",
    "dataset1=dataset1[is_dataset1]\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  textblob import TextBlob\n",
    "tweettext=dataset1['text']\n",
    "wordlist=pd.DataFrame();\n",
    "\n",
    "polarity=[]\n",
    "subj=[]\n",
    "\n",
    "for t in tweettext:\n",
    "    tx= TextBlob(t)\n",
    "    polarity.append(tx.sentiment.polarity)\n",
    "    subj.append(tx.sentiment.subjectivity)\n",
    "\n",
    "poltweet= pd.DataFrame({'polarity':polarity,'subjectivity':subj})\n",
    "poltweet.polarity.plot(title='Polarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poltweet.subjectivity.plot(title='Subjectivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "statistics.mean(poltweet.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "statistics.mean(poltweet.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction to get clean text to get better analysis\n",
    "def cleanText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "dataset1['text'] = dataset1['text'].apply(cleanText)\n",
    "\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction to get subjectivity and polarity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "dataset1['Subjectivity'] = dataset1['text'].apply(getSubjectivity)\n",
    "dataset1['Polarity'] = dataset1['text'].apply(getPolarity)\n",
    "\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute positive negative neutral analysis\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "dataset1['Analysis'] = dataset1['Polarity'].apply(getAnalysis)\n",
    "\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of positive\n",
    "ptweets = dataset1[dataset1.Analysis == 'Positive']\n",
    "ptweets = ptweets['text']\n",
    "\n",
    "round( (ptweets.shape[0] / dataset1.shape[0]) *100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of negative\n",
    "ntweets = dataset1[dataset1.Analysis == 'Negative']\n",
    "ntweets = ntweets['text']\n",
    "\n",
    "round( (ntweets.shape[0] / dataset1.shape[0]) *100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of neutral\n",
    "neutweets = dataset1[dataset1.Analysis == 'Neutral']\n",
    "neutweets = neutweets['text']\n",
    "\n",
    "round( (neutweets.shape[0] / dataset1.shape[0]) *100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1['Analysis'].value_counts()\n",
    "\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "dataset1['Analysis'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
